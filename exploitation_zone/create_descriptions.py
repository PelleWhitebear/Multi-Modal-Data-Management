import os
import logging
import json
from tqdm import tqdm
import dotenv
from google import genai
import time
from global_scripts.prompts import create_description_prompt
from global_scripts.utils import minio_init, gemini_init, query_gemini

dotenv.load_dotenv(dotenv.find_dotenv())

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] - %(message)s',
    force=True  # override any existing config
)

def main():

    # MinIO client connection, using Amazon S3 API and boto3 Python library
    s3_client = minio_init()

    # Gemini client connection, using Google GenAI Python library
    client = gemini_init()
    
    try:
        # Cannot use load_games_from_minio here since we need to check for today's file first
        create_descriptions = True
        logging.info("Fetching game data from MinIO...")
        objs = s3_client.list_objects_v2(Bucket=os.getenv("EXPLOITATION_ZONE_BUCKET"), Prefix="json/")
        logging.info(f"Objects found: {[obj['Key'] for obj in objs.get('Contents', [])]}")
        if "Contents" not in objs:
            logging.error("No game data found in MinIO.")
            return
        else:
            for obj in objs["Contents"]:
                # If theres a file from the same day, skip description creation
                if obj["Key"].endswith("enhanced_games.json") and f"{time.strftime('%Y%m%d')}" in obj["Key"]:
                    logging.info("Descriptions already created for today. Skipping description creation.")
                    create_descriptions = False
                if obj["Key"].endswith("merged_games.json"):
                    filename = obj["Key"]
                    logging.info(f"Game data file found: {filename}")
                    res = s3_client.get_object(Bucket=os.getenv("EXPLOITATION_ZONE_BUCKET"), Key=filename)
                    games = json.loads(res["Body"].read().decode("utf-8"))

    except Exception:
        logging.exception("Error getting game data from MinIO.")
        return

    # If we have already created descriptions today, delete everything but that file
    if not create_descriptions:
        try:
            objs = s3_client.list_objects_v2(Bucket=os.getenv("EXPLOITATION_ZONE_BUCKET"), Prefix="json/")
            if "Contents" not in objs:
                logging.error("No game data found in MinIO.")
                return
            for obj in objs["Contents"]:
                if not obj["Key"].endswith("enhanced_games.json") or not f"{time.strftime('%Y%m%d')}" in obj["Key"]:
                    logging.info(f"Deleting object: {obj['Key']}")
                    s3_client.delete_object(Bucket=os.getenv("EXPLOITATION_ZONE_BUCKET"), Key=obj["Key"])
        except Exception:
            logging.exception("Error deleting original game data file.")
            return
        
        logging.info("Descriptions already created for today. Exiting.")
        return
    
    # Create descriptions for each game using Gemini
    for game_id, game_data in tqdm(games.items(), desc="Creating descriptions"):
        logging.info(f"Processing game ID: {game_id}")
        game_input_data = {
                "name": game_data.get("name", ""),
                "detailed_description": game_data.get("detailed_description", ""),
                "short_description": game_data.get("short_description", ""),
                "genres": game_data.get("genres", []),
                "about_the_game": game_data.get("about_the_game", "")
            }

        game_data["final_description"] = query_gemini(client, game_input_data)
        time.sleep(int(os.getenv("TIME_SLEEP_GEMINI")))  # To avoid rate limiting

    # Upload the updated games with descriptions back to MinIO
    try:
        logging.info("Uploading updated game data to MinIO...")
        enhanced_filename = filename.split("#")[0] + "#enhanced_games.json"
        s3_client.put_object(Bucket=os.getenv("EXPLOITATION_ZONE_BUCKET"), Key=enhanced_filename, Body=json.dumps(games))
        logging.info("Uploaded game data successfully.")
    except Exception:
        logging.exception("Error uploading updated game data to MinIO.")
        return

    # Delete all files but today's enhanced_games.json
    try:
        objs = s3_client.list_objects_v2(Bucket=os.getenv("EXPLOITATION_ZONE_BUCKET"), Prefix="json/")
        if "Contents" not in objs:
            logging.error("No game data found in MinIO.")
            return
        for obj in objs["Contents"]:
            if not obj["Key"].endswith("enhanced_games.json") or not f"{time.strftime('%Y%m%d')}" in obj["Key"]:
                logging.info(f"Deleting object: {obj['Key']}")
                s3_client.delete_object(Bucket=os.getenv("EXPLOITATION_ZONE_BUCKET"), Key=obj["Key"])
    except Exception:
        logging.exception("Error deleting original game data file.")
        return

    logging.info("Description creation process completed.")
    return

if __name__ == "__main__":
    main()